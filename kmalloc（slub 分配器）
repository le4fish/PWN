linux内核在管理内存页面时，使用伙伴算法和slub算法。

1.伙伴算法以页为单位管理内存（默认为4k），但在大多数情况下，程序需要的并不是一整页，而是几个、几十个字节的小内存。

于是需要另外一套系统来完成对小内存的管理，这就是slub系统。slub系统运行在伙伴系统之上，为内核提供小内存管理的功能。

2.多年以来，SLAB成为linux kernel对象缓冲区管理的主流算法，甚至长时间没有人愿意去修改，因为它实在是非常复杂。
 
 但是，随着大规模多处理器系统和 NUMA系统的广泛应用，SLAB 分配器逐渐暴露出自身的严重不足：

    1). 缓存队列管理复杂；

    2). 管理数据存储开销大；

    3). 对NUMA支持复杂；

    4). 调试调优困难；

    5). 摒弃了效果不太明显的slab着色机制；

3.在Linux内核2.6.22版本中引入一种新的解决方案：SLUB分配器。

SLUB分配器特点是简化设计理念，同时保留SLAB分配器的基本思想：每个缓冲区由多个小的slab 组成，每个 slab 包含固定数目的对象。

SLUB分配器简化kmem_cache，slab等相关的管理数据结构，摒弃了SLAB 分配器中众多的队列概念，

并针对多处理器、NUMA系统进行优化，从而提高了性能和可扩展性并降低了内存的浪费。

为了保证内核其它模块能够无缝迁移到SLUB分配器，SLUB还保留了原有SLAB分配器所有的接口API函数。


## SLUB分配器的初始化

SLUB初始化有两个重要的工作：
第一，创建用于申请 struct kmem_cache 和 struct kmem_cache_node 的 kmem_cache；

第二，创建用于常规kmalloc的 kmem_cache 。 

ps1.因为创建 kmem_cache 需要从 kmem_cache 的缓冲区申请，而这时候还没有创建 kmem_cache 的缓冲区。

kernel 的解决办法是先用两个静态变量 boot_kmem_cache 和 boot_kmem_cache_node

来保存 struct kmem_cach 和 struct kmem_cache_node 缓冲区管理数据，

以两个静态变量为基础申请大小为 struct kmem_cache 和 struct kmem_cache_node 对象大小的slub缓冲区，

随后再从这些缓冲区中分别申请两个 kmem_cache ，然后把 boot_kmem_cache 和 boot_kmem_cache_node 中的内容拷贝到新申请的对象中，

从而完成了 struct kmem_cache 和 struct kmem_cache_node 管理结构的 bootstrap（自引导）。

ps2.创建kmalloc常规缓存：

原则上系统会为每个2次幂大小的内存块申请一个缓存，但是内存块过小时，会产生很多碎片浪费，所以系统为 96B 和 192B 也各自创建了一个缓存。

## slub的调度
kmem_cache 有两个“部分”，一个是“仓库”：kmem_cache_node，一个“现行”：kmem_cache_cpu。

“现行”里只保留一个slab，只有在 kmem_cache_cpu 中没有空闲内存的情况下才会从 kmem_cache_node 中换出其他的 slab

  物理页按照对象(object)大小组织成单向链表，对象大小时候objsize指定的。
  
  例如16字节的对象大小，每个object就是16字节，每个object包含指向下一个object的指针，该指针的位置是每个object的起始地址+offset。
